# Edgar-AI

**Automated, self-improving data extraction for SEC exhibits.**

Edgar-AI reads raw exhibits straight from EDGAR and turns them into clean,
query-ready tablesâ€”*without* hand-written regexes, templates, or routing rules.
An ensemble of LLM personas invents the goals, designs the schemas, extracts
the data, critiques itself, and learns from every document it touches.

> **Mission:** Make financial disclosure data instantly usable and keep the
> pipeline improving on its own, so analysts spend zero time on parsing and
> 100 % on insights.

---

## 1.  The Data Fly-Wheel

```text
                Raw HTML Filing
                         â”‚
                         â–¼
                    Intake
                         â”‚
                         â–¼
                 Goal-Setter (LLM)
                         â”‚   determines `goal_id`
                         â–¼
              â”Œâ”€â”€ Memory: schema? â”€â”€â”
              â”‚                     â”‚
        yes â”€â”€â”˜                     â””â”€â”€ no
          â”‚                           â”‚
          â–¼                           â–¼
  Prompt-Builder (warm)        Schema Variants  (max / mini / bal)
          â”‚                           â”‚
          â”‚                    Referee picks best
          â”‚                           â–¼
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ winning schema â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                    â–¼
                                           Prompt-Builder
                                                    â”‚
                                                    â–¼
                                              Extractor
                                                    â”‚  JSON rows + lineage
                                                    â–¼
                                                Critic
                                                    â”‚  feedback
                                                    â–¼
                                                Tutor
                                                    â”‚  improved prompt / schema
                                                    â””â”€â”€â–º Memory   (learning loop)

        Breaker (adversarial docs) feeds synthetic edge cases into Intake â†’
```

Every pass through the fly-wheel makes the extractor **faster, broader, and
more accurate**â€”all by prompt evolution, never by re-training model weights.

---

## 2.  Step-by-Step Workflow

1. **Goal-Setter** â€“ Reads only the exhibit text, decides the single most
   valuable analytical objective, and outputs a concise JSON goal.

2. **Schema lookup (warm-start)** â€“ If Memory already holds a schema whose
   goal_id matches the current document, we reuse it and jump **directly to
   extraction** â€“ saving three LLM calls.  Otherwise we enter the cold-start
   path:

   **Schema Variants** â€“ With the new prompt rules (observability, granularity,
   normal-form arrays), three candidate schemas are generated.

3. **Referee** â€“ Judges the variants against explicit criteria and saves the
   winner in a file-backed Memory store.  If none is adequate a merge path can
   be enabled (see `docs/referee_merge_strategy.md`).

4. **Prompt-Builder** â€“ Converts the schema into a deterministic extraction
   prompt, surfacing any nested `json_schema` so the LLM knows when to emit
   arrays of objects.

5. **Extractor** â€“ Large-context model returns structured JSON rows.  All
   prompts, model SHAs, and raw outputs are logged for provenance.

6. **Critic + Memory** â€“ Another persona re-reads the document and grades each
   cell, referencing past mistakes stored in Memory.  Feedback is appended to
   the rowâ€™s lineage.

7. **Tutor** â€“ When critic notes accumulate, the Tutor rewrites the schema or
   prompt section and submits a pull-request-style patch for human or automated
   approval (championâ€“challenger logic).

8. **Breaker** â€“ Generates synthetic edge cases designed to fail current
   prompts, feeding them back into the pipeline and forcing continual
   hardening.

---

## 3.  Why This Works

| Principle | Effect |
|-----------|--------|
| **Observability-first schemas** | Every field can be answered from the exhibit alone; reduces hallucination. |
| **Normal-form modelling** | Repeating concepts become arrays with their own mini-schemas, enabling arbitrarily deep structures. |
| **Critic-Tutor feedback** | Objective, row-level scores drive prompt evolution; fixes propagate automatically. |
| **Adversarial Breaker** | Synthetic documents surface edge cases *before* production filings change. |
| **Championâ€“Challenger governance** | New prompts/schemas must outperform current champion before promotion, preventing regressions. |

---

## 4.  Jump In

```bash
# Install (editable) & run a quick extract
pip install -e .
python -m edgar_ai.cli extract path/to/exhibit.txt --verbose
```

See `docs/` for deep-dive design notes; start with `docs/architecture.md`.

Happy parsing! ğŸ‰
